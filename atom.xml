<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://WalkingPineapple.github.io</id>
    <title>摇摇晃摇</title>
    <updated>2020-02-10T13:59:54.106Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://WalkingPineapple.github.io"/>
    <link rel="self" href="https://WalkingPineapple.github.io/atom.xml"/>
    <subtitle>黑夜给了我黑色眼睛，我却用它去寻找光明&lt;/br&gt;                                             
</subtitle>
    <logo>https://WalkingPineapple.github.io/images/avatar.png</logo>
    <icon>https://WalkingPineapple.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, 摇摇晃摇</rights>
    <entry>
        <title type="html"><![CDATA[图像金字塔]]></title>
        <id>https://WalkingPineapple.github.io/post/tu-xiang-jin-zi-ta</id>
        <link href="https://WalkingPineapple.github.io/post/tu-xiang-jin-zi-ta">
        </link>
        <updated>2020-02-10T13:58:04.000Z</updated>
        <content type="html"><![CDATA[<h2 id="图像金字塔">图像金字塔</h2>
<p>高分辨率图像产生的低分辨率图像集合。</p>
<figure data-type="image" tabindex="1"><img src="https://WalkingPineapple.github.io/post-images/1581343121950.png" alt="" loading="lazy"></figure>
<h3 id="高斯金字塔">高斯金字塔</h3>
<pre><code>将原图像不断使用高斯滤波器进行滤波，将滤波图像删除偶数行和偶数列删除（向下采样），通过向下采样，原图像像素值丢失，分辨率减小。
dst=cv2.pyrdown(src,dstsize,borderType)
- src:原图像
- dstsize：目标图像，可选参数，默认情况下，输出图像的大小为Size((src.cols+1)/2, (src.rows+1)/2)
- borderType：边框
</code></pre>
<p><strong>实际代码演示</strong></p>
<pre><code class="language-python">down=cv2.pyrDown(img)
img_show('down',down)
print(down.shape)
</code></pre>
<pre><code>同时， 向上采样则是通过新值为零的行和列，在用先前的卷积核*4和放大的图像卷积，保证我们得到的像素值都在[0,255]以内
</code></pre>
<p>dst=cv2.pyrup(src,dstsize,borderType)<br>
- src:原图像<br>
- dstsize：目标图像，可选参数，默认情况下，输出图像的大小为Size(src.col<em>2, src.rows</em>2)<br>
- borderType：边框<br>
<strong>实际代码演示</strong></p>
<pre><code class="language-python">#向上采样
up=cv2.pyrUp(img)
img_show('up',up)
print(up.shape)
</code></pre>
<p><img src="https://WalkingPineapple.github.io/post-images/1581343142999.png" alt="" loading="lazy"><br>
PS:向下采样和向上采样的操作都是不可逆的。</p>
<h3 id="拉普拉斯金字塔">拉普拉斯金字塔</h3>
<p>通过拉普拉斯金字塔，我们可以向上采样的时能够恢复较高的原始图像。具体操作如下：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">L</mi><mi mathvariant="normal">i</mi></msub><mo>=</mo><msub><mi mathvariant="normal">G</mi><mi mathvariant="normal">i</mi></msub><mo>−</mo><mrow><mi mathvariant="normal">P</mi><mi mathvariant="normal">y</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">U</mi><mi mathvariant="normal">p</mi></mrow><mrow><mo fence="true">(</mo><mrow><mi mathvariant="normal">P</mi><mi mathvariant="normal">y</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">D</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">w</mi><mi mathvariant="normal">n</mi></mrow><mrow><mo fence="true">(</mo><msub><mi mathvariant="normal">G</mi><mi mathvariant="normal">i</mi></msub><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm{L}_{\mathrm{i}}=\mathrm{G}_{\mathrm{i}}-\mathrm{PyrUp}\left(\mathrm{PyrDown}\left(\mathrm{G}_{\mathrm{i}}\right)\right)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">L</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31750199999999995em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">i</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">G</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31750199999999995em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">i</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathrm">P</span><span class="mord mathrm" style="margin-right:0.01389em;">y</span><span class="mord mathrm">r</span><span class="mord mathrm">U</span><span class="mord mathrm">p</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathrm">P</span><span class="mord mathrm" style="margin-right:0.01389em;">y</span><span class="mord mathrm">r</span><span class="mord mathrm">D</span><span class="mord mathrm">o</span><span class="mord mathrm" style="margin-right:0.01389em;">w</span><span class="mord mathrm">n</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord"><span class="mord mathrm">G</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31750199999999995em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">i</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span></span></p>
<ul>
<li>Li：拉普拉斯金字塔第i层</li>
<li>Gi：高斯金字塔的第i层<br>
<img src="https://WalkingPineapple.github.io/post-images/1581343155632.png" alt="" loading="lazy"><br>
<strong>实际代码演示</strong></li>
</ul>
<pre><code class="language-python">#拉普拉斯金字塔
up_1=cv2.pyrUp(down)
result=img-up_1
img_show('result',result)
print(result.shape)
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Canny边缘检测]]></title>
        <id>https://WalkingPineapple.github.io/post/canny-bian-yuan-jian-ce</id>
        <link href="https://WalkingPineapple.github.io/post/canny-bian-yuan-jian-ce">
        </link>
        <updated>2020-02-09T08:40:01.000Z</updated>
        <content type="html"><![CDATA[<h2 id="canny边缘检测">Canny边缘检测</h2>
<pre><code>1.通过高斯滤波器（算子）来去除图像噪声（噪声会影响检测的准确性）
2.计算梯度的幅度和方向
3.使用“非极大值抑制” 消除边缘检测来的杂散响应
4.使用双阈值算法来确定边缘
</code></pre>
<h3 id="1高斯滤波去噪">1.高斯滤波去噪</h3>
<pre><code>使用高斯滤波的目的就是平滑一些较弱的非边缘区域,滤波器的核越大，边缘信息对于噪声的敏感度就越低， 检测错误也会随之增加
</code></pre>
<h3 id="2梯度计算">2.梯度计算</h3>
<pre><code>原始图像的边缘的方向是不同的，使用梯度算子来分别计算水平、垂直、对角线的方向梯度，因为梯度方向与边缘是垂直的，在梯度计算中，我么你可以计算出水平方向的Gx和垂直方向Gy，所以：
</code></pre>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mtable><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi mathvariant="normal">G</mi><mo>=</mo><msqrt><mrow><msubsup><mi>G</mi><mi>x</mi><mn>2</mn></msubsup><mo>+</mo><msubsup><mi>G</mi><mi>y</mi><mn>2</mn></msubsup></mrow></msqrt></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi>θ</mi><mo>=</mo><mi mathvariant="normal">atan</mi><mo>⁡</mo><mn>2</mn><mrow><mo fence="true">(</mo><msub><mi>G</mi><mi>y</mi></msub><mo separator="true">,</mo><msub><mi>G</mi><mi>x</mi></msub><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
&amp;\mathrm{G}=\sqrt{G_{x}^{2}+G_{y}^{2}}\\
&amp;\theta=\operatorname{atan} 2\left(G_{y}, G_{x}\right)
\end{aligned}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.6400000000000006em;vertical-align:-1.5700000000000003em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.0700000000000003em;"><span style="top:-4.07em;"><span class="pstrut" style="height:3.212375em;"></span><span class="mord"></span></span><span style="top:-2.302375em;"><span class="pstrut" style="height:3.212375em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5700000000000003em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.0700000000000003em;"><span style="top:-4.07em;"><span class="pstrut" style="height:3.212375em;"></span><span class="mord"><span class="mord"></span><span class="mord"><span class="mord mathrm">G</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2123750000000002em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.740108em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7401079999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.1723749999999997em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em;"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M1001,80H400000v40H1013.1s-83.4,268,-264.1,840c-180.7,
572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,
-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744c-10,12,-21,25,-33,39s-32,39,-32,39
c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30c26.7,-32.7,52,-63,76,-91s52,-60,52,-60
s208,722,208,722c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,
-658.5c53.7,-170.3,84.5,-266.8,92.5,-289.5c4,-6.7,10,-10,18,-10z
M1001 80H400000v40H1013z'/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6276249999999999em;"><span></span></span></span></span></span></span></span><span style="top:-2.302375em;"><span class="pstrut" style="height:3.212375em;"></span><span class="mord"><span class="mord"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mop"><span class="mord mathrm">a</span><span class="mord mathrm">t</span><span class="mord mathrm">a</span><span class="mord mathrm">n</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5700000000000003em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<h3 id="3非极大值抑制">3.非极大值抑制</h3>
<figure data-type="image" tabindex="1"><img src="https://WalkingPineapple.github.io/post-images/1581237806396.png" alt="" loading="lazy"></figure>
<pre><code>从图中可以得到，A、B 、C 三个点都具有相同水平方向（梯度方向垂直于边缘），我们只需要判断三个点是或否为各自局部的最大值，如果是，保留，反之，则抑制（置0），通过非极大值抑制，就可以使边缘更加细化。
</code></pre>
<h3 id="4双阈值确定边缘">4.双阈值确定边缘</h3>
<p>通过设定两个阈值：高阈值（maxVal）低阈值（minVal），用梯度幅度和这个两个比较，就可以判断边缘属性。</p>
<p><img src="https://WalkingPineapple.github.io/post-images/1581237824221.png" alt="" loading="lazy"><br>
结合图像，A点的梯度值大于maxVal,则归为边界，B点，介于maxVal和minVal中间，并且与边界相连，所以保留，C点同时介于中间，但不相连，则抛弃，D点小于minVal，则抛弃。<br>
通过阈值处理后，可以将梯度较小的点排除，让边缘更加细化。</p>
<h3 id="canny函数">Canny函数</h3>
<pre><code>edges=cv2.Canny(img,threshold1,threshold2,apertureSize,L2gradient)
- edges:返回值，边缘图像
- image:输入的8位图像
- threshold1：第一个阈值
- threshold2：第二个阈值
- apertureSize：算子的维度
- L2gradient：计算图像梯度幅度标识，默认值为False，如果为True，则使用L2	范数进行计算（更精确）
</code></pre>
<p><strong>实际代码演示</strong><br>
原始图像：</p>
<figure data-type="image" tabindex="2"><img src="https://WalkingPineapple.github.io/post-images/1581237833705.jpg" alt="" loading="lazy"></figure>
<pre><code class="language-python">img=cv2.imread(&quot;timg.jpg&quot;,cv2.IMREAD_GRAYSCALE)
img_show(&quot;img&quot;,img)

canny1=cv2.Canny(img,200,400)
canny2=cv2.Canny(img,50,100)

res = np.hstack((canny1,canny2))
img_show('res',res)
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://WalkingPineapple.github.io/post-images/1581237841858.png" alt="" loading="lazy"></figure>
<p>如果将两个阈值设偏小时，边缘检测会更细腻，捕获的的信息越多。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[图像处理（二）]]></title>
        <id>https://WalkingPineapple.github.io/post/tu-xiang-chu-li-er</id>
        <link href="https://WalkingPineapple.github.io/post/tu-xiang-chu-li-er">
        </link>
        <updated>2020-02-08T10:15:47.000Z</updated>
        <content type="html"><![CDATA[<h2 id="图像处理-二">图像处理 （二）</h2>
<h3 id="开运算">开运算</h3>
<pre><code>先腐蚀，后膨胀（去噪 、计数）
opening=cv2.morphologyEx(img,cv2.MORPH_OPEN,kernel)
- opening:返回值，开运算返回后图像
- img：原图像
- kernel：核函数
</code></pre>
<p><strong>实际代码演示</strong></p>
<pre><code class="language-python">opening=cv2.morphologyEx(thresh2,cv2.MORPH_OPEN,kernel)
img_show(&quot;opening&quot;,opening)
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://WalkingPineapple.github.io/post-images/1581157587418.png" alt="" loading="lazy"></figure>
<h3 id="闭运算">闭运算</h3>
<pre><code>先膨胀，后腐蚀（去除小黑点）
closing=cv2.morphologyEx(img,cv2.MORPH_OPEN,kernel)
- closing:返回值，开运算返回后图像
- img：原图像
- kernel：核函数
</code></pre>
<p><strong>实际代码演示</strong></p>
<pre><code class="language-python">closing=cv2.morphologyEx(thresh2,cv2.MORPH_CLOSE,kernel)
img_show(&quot;closing&quot;,closing)
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://WalkingPineapple.github.io/post-images/1581157595122.png" alt="" loading="lazy"></figure>
<h3 id="梯度运算">梯度运算</h3>
<pre><code>用图像的膨胀后图像减去腐蚀操作的图像（获取原始图像的前景图像边缘）
result=cv2.morphologyEx(img,cv2.MORPH_GRADIENT,kernel)
- result:返回值，梯度元素后返回后的图像
- img：原图像
- kernel：核函数
</code></pre>
<p><strong>实际代码演示</strong></p>
<pre><code class="language-python">result=cv2.morphologyEx(thresh2,cv2.MORPH_GRADIENT,kernel)
img_show(&quot;grad&quot;,result)
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://WalkingPineapple.github.io/post-images/1581157616087.png" alt="" loading="lazy"></figure>
<h3 id="礼帽运算">礼帽运算</h3>
<pre><code>原始图像减开运算图像的操作（获取图像噪声、得到比原始图像边缘更亮的边缘信息）
result=cv2.morphologyEx(img,cv2.MORPH_TOPHAT,kernel)
- result:返回值，礼帽元素后返回后的图像
- img：原图像
- kernel：核函数
</code></pre>
<p><strong>实际代码演示</strong></p>
<pre><code class="language-python">#礼帽运算
result=cv2.morphologyEx(thresh2,cv2.MORPH_TOPHAT,kernel)
img_show(&quot;TopHat&quot;,result)
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://WalkingPineapple.github.io/post-images/1581157627588.png" alt="" loading="lazy"></figure>
<h3 id="黑帽运算">黑帽运算</h3>
<pre><code>闭运算减原始图像操作（获取图像的小黑点、得到比院士图像边缘更暗的边缘信息）
result=cv2.morphologyEx(img,cv2.MORPH_BLACKHAT,kernel)
- result:返回值，礼帽元素后返回后的图像
- img：原图像
- kernel：核函数
</code></pre>
<p><strong>实际代码演示</strong></p>
<pre><code class="language-python">#黑帽运算
result=cv2.morphologyEx(thresh2,cv2.MORPH_BLACKHAT,kernel)
img_show(&quot;BlackHat&quot;,result)
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://WalkingPineapple.github.io/post-images/1581157699138.png" alt="" loading="lazy"></figure>
<h3 id="图像梯度">图像梯度</h3>
<p>图像梯度就是图像的变化速度，对于图像的边缘来说，梯度越大，变化越大（计算图像边缘信息）对于任意边界，如果右侧（上侧）像素值与左侧（下侧）像素值差值为0，则为边界，反之，则不是。</p>
<h4 id="sobel算子">Sobel算子</h4>
<pre><code>利用局部差找边界，计算结果为梯度一个近似值
</code></pre>
<figure data-type="image" tabindex="6"><img src="https://WalkingPineapple.github.io/post-images/1581157719131.png" alt="" loading="lazy"></figure>
<pre><code>图像的梯度计算简单来说就是求导，那水平方向Gx的偏导数如下：
</code></pre>
<figure data-type="image" tabindex="7"><img src="https://WalkingPineapple.github.io/post-images/1581157735072.png" alt="" loading="lazy"></figure>
<pre><code>垂直方向Gy的偏导数如下：
</code></pre>
<figure data-type="image" tabindex="8"><img src="https://WalkingPineapple.github.io/post-images/1581157746497.png" alt="" loading="lazy"></figure>
<pre><code>dst = cv2.Sobel(src, ddepth, dx, dy, ksize，scale，delta)
- ddepth:图像的深度，通常在实际计算中，可能会出现负数，如果处理的事8位图，ddepth设置为-1，则负数就会截断为0，所以，我们在计算时候使用更高的数据类型cv2.CV_64F,并通过convertScaleAbs取绝对值即可。
- dx和dy分别表示水平和竖直方向求导阶数
- ksize：Sobel算子的大小 为-1时，则使用Scharr算子进行计算
- scale：计算导数时的缩放因子，默认为1，则无缩放
- delta：加在目标图像的值，默认为0
</code></pre>
<p><strong>实际代码演示</strong></p>
<pre><code class="language-python">#水平方向

sobelx=cv2.Sobel(thresh2,cv2.CV_64F,1,0,ksize=3)
sobelxAbsx=cv2.convertScaleAbs(sobelx)
img_show(&quot;sobelx&quot;,sobelxAbsx)
#垂直方向
sobely=cv2.Sobel(thresh2,cv2.CV_64F,0,1,ksize=3)
sobelxAbsy=cv2.convertScaleAbs(sobely)
img_show(&quot;sobely&quot;,sobelxAbsy)
# 计算水平方向和垂直方向的边界叠加和
sobelxy=cv2.addWeighted(sobelxAbsy,0.5,sobelxAbsy,0.5,0)
img_show(&quot;sobelxy&quot;,sobelxy)
</code></pre>
<figure data-type="image" tabindex="9"><img src="https://WalkingPineapple.github.io/post-images/1581157774306.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="10"><img src="https://WalkingPineapple.github.io/post-images/1581157783328.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="11"><img src="https://WalkingPineapple.github.io/post-images/1581157793149.png" alt="" loading="lazy"></figure>
<h4 id="scharr算子">Scharr算子</h4>
<pre><code>Sobel的改进，提高了精度。
</code></pre>
<figure data-type="image" tabindex="12"><img src="https://WalkingPineapple.github.io/post-images/1581157807514.png" alt="" loading="lazy"></figure>
<pre><code>dst = cv2.Scharr(src, ddepth, dx, dy, ksize，scale，delta)
- ddepth:图像的深度，通常在实际计算中，可能会出现负数，如果处理的事8位图，ddepth设置为-1，则负数就会截断为0，所以，我们在计算时候使用更高的数据类型cv2.CV_64F,并通过convertScaleAbs取绝对值即可。
- dx和dy分别表示水平和竖直方向求导阶数
- scale：计算导数时的缩放因子，默认为1，则无缩放
- delta：加在目标图像的值，默认为0
</code></pre>
<p><strong>实际代码演示</strong></p>
<pre><code class="language-python">#水平方向
scharrx=cv2.Scharr(thresh2,cv2.CV_64F,1,0)
scharrAbsx=cv2.convertScaleAbs(sobelx)
img_show(&quot;scharrx&quot;,scharrAbsx)
#垂直方向
scharry=cv2.Scharr(thresh2,cv2.CV_64F,1,0)
scharrAbsy=cv2.convertScaleAbs(sobely)
img_show(&quot;scharry&quot;,scharrAbsy)

## 计算水平方向和垂直方向的边界叠加和
scharrxy=cv2.addWeighted(scharrAbsx,0.5,scharrAbsy,0.5,0)
img_show(&quot;scharrxy&quot;,scharrxy)
</code></pre>
<figure data-type="image" tabindex="13"><img src="https://WalkingPineapple.github.io/post-images/1581157830308.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="14"><img src="https://WalkingPineapple.github.io/post-images/1581157836312.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="15"><img src="https://WalkingPineapple.github.io/post-images/1581157840927.png" alt="" loading="lazy"></figure>
<h4 id="laplacian算子">Laplacian算子</h4>
<pre><code>简单来说，就是求二阶导数，虽案子的系数之和需要为0(满足不同图像的边缘锐化)
</code></pre>
<p><img src="https://WalkingPineapple.github.io/post-images/1581157862262.png" alt="" loading="lazy"><br>
dst = cv2.Laplacian(src, ddepth,  ksize，scale，delta)<br>
- ddepth:图像的深度<br>
- ksize：Sobel算子的大小 为-1时，则使用Scharr算子进行计算<br>
- scale：计算导数时的缩放因子，默认为1，则无缩放<br>
- delta：加在目标图像的值，默认为0<br>
<strong>实际代码演示</strong></p>
<pre><code class="language-python">#Laplacian算子
laplacian=cv2.Laplacian(thresh2,cv2.CV_64F)
laplacianAbs=cv2.convertScaleAbs(laplacian)
img_show(&quot;laplacian&quot;,laplacianAbs)
</code></pre>
<figure data-type="image" tabindex="16"><img src="https://WalkingPineapple.github.io/post-images/1581157870764.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[图像处理（一）]]></title>
        <id>https://WalkingPineapple.github.io/post/tu-xiang-chu-li-yi</id>
        <link href="https://WalkingPineapple.github.io/post/tu-xiang-chu-li-yi">
        </link>
        <updated>2020-02-07T14:01:32.000Z</updated>
        <content type="html"><![CDATA[<h2 id="图像处理">图像处理</h2>
<h3 id="图像阈值">图像阈值</h3>
<pre><code>阈值处理是剔除图像内像素值高于一定之或者低于一定值的像素点，通常阈值由我们自己设定。
</code></pre>
<h4 id="threeshold函数">threeshold函数</h4>
<p>ret, dst = cv2.threshold(src, thresh, maxval, type)</p>
<ul>
<li>src： 输入图，只能输入单通道图像，通常来说为灰度图</li>
<li>dst： 输出图</li>
<li>thresh： 阈值</li>
<li>maxval： 当像素值超过了阈值（或者小于阈值，根据type来决定），所赋予的值</li>
<li>type：二值化操作的类型，包含以下5种类型：</li>
</ul>
<ol>
<li>cv2THRESH_BINARY:大于阈值就取最大值；否则取0</li>
<li>cv2.THRESH_BINARY_INV:大于取0 否则取最大值</li>
<li>cv2.THRESH_TRUNC：大于阈值的部份则取阈值，否则不变</li>
<li>cv2.THRESH_TOZERO：大于阈值不变，否则取0</li>
<li>cv2.THRESH_TOZERO_INV：大于阈值取0，否则不变<br>
<strong>实际代码演示</strong></li>
</ol>
<pre><code class="language-python">
import cv2
import numpy
import matplotlib.pyplot as plt
def img_show(name,img):
cv2.imshow('name',img)
cv2.waitKey(0)
cv2.destroyAllWindows()
img=cv2.imread(&quot;car.jpg&quot;,cv2.IMREAD_GRAYSCALE)
img_show(&quot;car&quot;,img)
#阈值处理
#只能处理灰度图像
ret, thresh1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)
ret, thresh2 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)
ret, thresh3 = cv2.threshold(img, 127, 255, cv2.THRESH_TRUNC)
ret, thresh4 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO)
ret, thresh5 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO_INV)
img_show(&quot;binary&quot;,thresh1)
img_show(&quot;binary_inv&quot;,thresh2)
img_show(&quot;trunc&quot;,thresh3)
img_show(&quot;tozero)&quot;,thresh4)
img_show(&quot;tozero_inv&quot;,thresh5)
</code></pre>
<h3 id="图像平滑">图像平滑</h3>
<pre><code>在保留图像原有信息的条件下，过滤图像内部噪声
</code></pre>
<p><img src="%7B$WP_ASSETS%7D/94e104481b6140d46b6c930535966ede.png" alt="" loading="lazy"><br>
平滑操作就是处理图像中周围像素点差异较大的像素点</p>
<h4 id="均值滤波">均值滤波</h4>
<pre><code>用均值来代替差异像素值
</code></pre>
<p>dst=cv2.blur(src,ksize,anchor,borderType)</p>
<ul>
<li>dst：返回值，均值滤波后图像</li>
<li>src：准备处理的图像</li>
<li>ksize：滤波核大小：均值处理，领域图像的高度和宽度，就是我们要选取的m和n</li>
<li>anchor:锚点，默认值（-1,1），表示当前计算均值的点位于核中的中心点位置，一般默认即可</li>
<li>borderType：边界样式<br>
<strong>实际代码演示</strong></li>
</ul>
<pre><code class="language-python">#均值滤波
blur = cv2.blur(img, (3, 3))
img_show(&quot;blur&quot;,blur)

</code></pre>
<h4 id="方框滤波">方框滤波</h4>
<pre><code>与均值滤波类似，可以自由是对领域像素值求均值，还是领域像素值之和
</code></pre>
<p>dst=cv2.boxFilter(src,ddepth,ksizie,anchor,normalize,borderType)</p>
<ul>
<li>dst：返回值，方框滤波后图像</li>
<li>src：准备处理的图像</li>
<li>ddepth:处理图像深度，一般用-1表示与原始图像使用相同的深度</li>
<li>ksize：滤波核大小：均值处理，领域图像的高度和宽度，就是我们要选取的m和n</li>
<li>anchor:锚点，默认值（-1,1），表示当前计算均值的点位于核中的中心点位置，一般默认即可</li>
<li>normalize 表示结果是否归一化，如果为真，则求均值，为假，直接使用领域像素和</li>
<li>borderType：边界样式<br>
<strong>实际代码演示</strong></li>
</ul>
<pre><code class="language-python"># 方框滤波
box = cv2.boxFilter(img,-1,(3,3), normalize=True)
img_show(&quot;box&quot;,box)
</code></pre>
<h4 id="高斯滤波">高斯滤波</h4>
<pre><code>将中心点的权重值加大，远离中心点的权重值减小，再基础上计算领域内各个像素值不同权重的和.
dst=cv2.GaussianBlur(src,ksize,sigmaX,sigmaY,borderType)
</code></pre>
<ul>
<li>dst：返回值，高斯滤波后图像</li>
<li>src：准备处理的图像</li>
<li>ksize：滤波核大小：均值处理，领域图像的高度和宽度，就是我们要选取的m和n</li>
<li>sigmaX:卷积核水平上标准差，</li>
<li>sigmaY:卷积核垂直上标准差，如果设为0，则使用sigmaX，两者都为零时，在通过计算卷积核的长度和宽度计算得到</li>
<li>
<ul>
<li>borderType：边界样式<br>
<strong>实际代码演示</strong></li>
</ul>
</li>
</ul>
<pre><code class="language-python"># 高斯滤波
gaussian = cv2.GaussianBlur(img, (5, 5), 1)
img_show(&quot;gaussian&quot;,gaussian)
</code></pre>
<h4 id="中值滤波">中值滤波</h4>
<pre><code>采用领域内所有像素值的中间值来代替当前像素点的值（排序）
</code></pre>
<p>dst=cv2.medianBlur(src,ksize)</p>
<ul>
<li>dst：返回值，中值滤波后图像</li>
<li>src：准备处理的图像</li>
<li>ksize：滤波核大小：均值处理，领域图像的高度和宽度，就是我们要选取的m和n,必须为奇数<br>
<strong>实际代码演示</strong></li>
</ul>
<pre><code class="language-python">#中值滤波
median = cv2.medianBlur(img, 5)  
img_show(&quot;median&quot;,median)
</code></pre>
<h3 id="腐蚀">腐蚀</h3>
<pre><code>将图像边界点消除，使图像沿着边界点向内收缩，腐蚀操作对逐个像素点来决定值，每次判断点都是和结构元中心所对应的点，简单来说，腐蚀操作就是背景色扩大，前景色收缩操作
</code></pre>
<p>dst=cv2.erode(src,kernel[,anchor[,iterations[,borderType[,borderValue]]]])</p>
<ul>
<li>dst：返回值，腐蚀后图像</li>
<li>src：准备处理的图像</li>
<li>kernel:腐蚀操作是采用结构类型，可以自定义或者通过cv2.getStructuringElement()生成</li>
<li>anchor：锚点，默认（-1,1）核中心位置</li>
<li>iteration：腐蚀操作的迭代次数，默认情况下为1</li>
<li>borderType：边界样式<br>
<strong>实际代码演示</strong></li>
</ul>
<pre><code class="language-python">#腐蚀操作
kernel = np.ones((7,7),np.uint8)
erosion = cv2.erode(thresh2,kernel,iterations = 1)

img_show('erosion',erosion)
</code></pre>
<h3 id="膨胀">膨胀</h3>
<pre><code>对图像边界进行扩展，与腐蚀相反，膨胀操作前景色扩大，背景色收缩
</code></pre>
<p>dst=cv2.dilate(src,kernel[,anchor[,iterations[,borderType[,borderValue]]]])</p>
<ul>
<li>dst：返回值，膨胀后图像</li>
<li>src：准备处理的图像</li>
<li>kernel:膨胀操作是采用结构类型，可以自定义或者通过cv2.getStructuringElement()生成</li>
<li>anchor：锚点，默认（-1,1）核中心位置</li>
<li>iteration：膨胀操作的迭代次数，默认情况下为1</li>
<li>borderType：边界样式<br>
<strong>实际代码演示</strong></li>
</ul>
<pre><code class="language-python">#膨胀操作
kernel = np.ones((7,7),np.uint8)
dilate= cv2.dilate(thresh2,kernel,iterations = 1)

img_show('dilate',dilate)
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Getting Started with Videos-文档翻译]]></title>
        <id>https://WalkingPineapple.github.io/post/getting-started-with-videos-wen-dang-fan-yi</id>
        <link href="https://WalkingPineapple.github.io/post/getting-started-with-videos-wen-dang-fan-yi">
        </link>
        <updated>2020-01-04T15:37:34.000Z</updated>
        <summary type="html"><![CDATA[<p><strong>题注：在学习图像识别时，看到这篇文章，但无奈英语太渣，就自己翻译了一篇</strong></p>
<h2 id="视频入门">视频入门</h2>
<h3 id="目标">目标</h3>
]]></summary>
        <content type="html"><![CDATA[<p><strong>题注：在学习图像识别时，看到这篇文章，但无奈英语太渣，就自己翻译了一篇</strong></p>
<h2 id="视频入门">视频入门</h2>
<h3 id="目标">目标</h3>
<!-- more -->
<ul>
<li>学习读取视频，播放视频和保存视频</li>
<li>学习从相机中捕捉视频并且播放视频</li>
<li>你讲学习到两个函数 cv2.videoCapture(),cv2.ViedoWriter()</li>
</ul>
<h3 id="从相机中捕捉视频">从相机中捕捉视频</h3>
<p>通常，我们必须用摄像机捕捉直播流。OpenCV为此提供了一个非常简单的接口。让我们从摄像机中捕获一个视频(我正在使用我的笔记本电脑内置的网络摄像头)，将它转换成灰度视频并显示出来。而我们的任务刚刚开始。</p>
<p>为了捕获视频，你需要一个创建一个<strong>VedioCapture</strong>对象，它的参数可以是设备的索引或者视频文件名字，设备索引只是用来选择我们使用哪个摄像头，通常，我们只会去连接一个摄像头，我们可以传入<strong>0</strong> 或 <strong>-1</strong>，当然，你也可以通过传递<strong>1</strong>去选择第二个摄像头，之后你就可以逐帧捕获，最后不要忘记将它释放了</p>
<pre><code class="language-python"># 导入模块
import numpy as npimport cv2
#OpenCv的版本是3.X.X，但是为什么要导入CV2 ？
# cv2表示使用的是C++的API，历史 遗留问题
.# 创建一个视频捕捉对象
cap=cv2.VideoCapture(0)
while(True):   
# 捕捉一帧  
ret,frame=cap.read()    
# 对帧进行操作    
gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)   
# 显示结果  
cv2.imshow('frame',gray)  
if cv2.waitKey(1) &amp; 0xFF == ord('q'):     
break        
# 释放摄像头    
cap.release() 
cv2.destroyAllWindows()
</code></pre>
<p>cap.read() 返回的是一个布尔值（True/False），如果我们捕捉到视频能够被正确的读取，它返回真，反之则为假，当然，你也可以通过它来检查视频的结尾。<br>
有些时候 ，cap对象的捕获可能沒有初始化，遇到这种情况，代码会报错，你可以通过<strong>cap.isOpened()</strong> 方法来检查是否初始化，如果返回真，则初始化，否则要使用<strong>cap.open（）</strong> 完成初始化。<br>
你也可以通过cap.get(propld)去查看一些视频的属性，propld是一个从0到18的数字，每个数字都代表了一个视频的属性（如果它适用于该视频） ，具体的数值参数可以查阅openCV官网，其中一些值，我们可以通过cap.set(propld,value)来修改你想要的值。</p>
<p>例如，我可以通过cap.get(3)和cap.get(4)来检查帧的宽度和高度。默认是640x480。但是我想修改成320x240。只需要使用ret = cap.set(3,320)和ret = cap.set(4,240)。</p>
<pre><code>注意：如果你遇到了错误，请确保使用任何其他相机应用程序(如Linux中的Cheese)相机都能正常工作。
</code></pre>
<h3 id="播放视频文件">播放视频文件</h3>
<p>和相机捕获一样，只用去更改相机的缩印和视频的文件名字即可，在我们显示帧的时候，用若干时间来等待目标对象<strong>cv2.waitKey()</strong>,如果太低，视频播放将很快，如果太高了，则视频播放很慢（这就是慢动作处理的方法，通常情况下，25毫秒即可），</p>
<pre><code class="language-python">
#导入模块
import numpy as np
import cv2
#加载视频
cap=cv2.VideoCapture('demo.mp4')
while(True):   
ret,frame=cap.read()  
gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY) 
cv2.imshow('frame',gray) 
if cv2.waitKey(3) &amp; 0xFF == ord('q'):    
    break
cap.release()
cv2.destroyAllWindows()
</code></pre>
<pre><code>注意：确保安装了正确版本的ffmpeg或gstreamer。有时，由于ffmpeg/gstreamer的错误安装，使用视频捕获非常麻烦。
</code></pre>
<h3 id="保存视频">保存视频</h3>
<p>对于我们捕获的视频，我们想保存他，对于图像，很简单，使用<strong>cv2.imwrite()</strong> ，这里需要多做一点工作。<br>
这次我们创建了一个视频写入对象<strong>VedioWrite()</strong> ,我们应该去指定我们输出的文件名字<br>
(eg: output.avi)，然后我们再指定一个FourCC码（具体看下面介绍），然后我们传递每秒帧数(fps)和帧大小。最后一个是<strong>isColor</strong><br>
标志。如果为True，则编码为色彩帧，否则将编码为灰度帧。</p>
<p>FourCC是一个4字符编码码，用于指定视频编解码器。可用代码的列表可以在fourcc.org上可以找到。它依赖于平台。遵循编解码器对我来说是可行的。</p>
<ul>
<li>对于Fedora: DIVX, XVID, MJPG, X264, WMV1, WMV2。(XVID的更好。MJPG的结果是大尺寸的视频。X264视频非常小)</li>
<li>对于Windows：DIVX(有待测试和增加)</li>
<li>对于OS:未测试<br>
FourCC编码，对于MJPG格式可以用cv2.VideoWriter_fourcc('M'，'J'，'P'，'G')或cv2.VideoWriter_fourcc(* ' MJPG ) 的形式传递。<br>
下面的代码从相机捕获并且把每一帧从垂直方向上保存。</li>
</ul>
<pre><code class="language-python"># 导入模块

import numpy as np
import cv2

cap = cv2.VideoCapture(0)

# 定义编码格式，并且创建VideoWriter对象

fourcc = cv2.VideoWriter_fourcc(*'XVID')
out = cv2.VideoWriter('demo1.avi',fourcc,-1,  (640,480))
while(cap.isOpened()):
    ret, frame = cap.read()
    if ret==True:
        frame = cv2.flip(frame,1)

        # 写入帧
        out.write(frame)

        cv2.imshow('frame',frame)
        if cv2.waitKey(1) &amp; 0xFF == ord('q'):
            break
    else:
        break

# 释放
cap.release()
out.release()
cv2.destroyAllWindows()
</code></pre>
<p>**附：源地址：https://docs.opencv.org/3.0beta/doc/py_tutorials/py_gui/py_video_display/py_video_display.html **</p>
]]></content>
    </entry>
</feed>